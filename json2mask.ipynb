{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Convert labelme annotation file to LIP parsing mask image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2880/2880 [00:01<00:00, 2397.31it/s]\n"
     ]
    }
   ],
   "source": [
    "image_label_dir = \"./안양_훈련_전체\"\n",
    "mask_out_dir = \"./안양_훈련_LIP형태\"\n",
    "\n",
    "if not os.path.exists(mask_out_dir):\n",
    "    os.mkdir(mask_out_dir)\n",
    "\n",
    "classes = {\"Upper-clothes\": 5,\n",
    "           \"Pants\": 9,\n",
    "           \"Skirt\": 12,\n",
    "           \"Dress\": 6}\n",
    "\n",
    "for filename in tqdm(os.listdir(image_label_dir)):\n",
    "    if \".json\" in filename:\n",
    "\n",
    "        # load json_file\n",
    "        json_file = open(os.path.join(image_label_dir, filename))\n",
    "        json_data = json.loads(json_file.read())\n",
    "\n",
    "        # load corresponding image\n",
    "        # img = cv2.imread(os.path.join(image_label_dir, filename.replace(\".json\", \".png\")))\n",
    "        h, w = json_data[\"imageHeight\"], json_data[\"imageWidth\"]\n",
    "        mask_img = np.zeros((h, w, 3), np.int32)\n",
    "\n",
    "        # parse all shapes and make mask image in LIP annotation format\n",
    "        for shape in json_data[\"shapes\"]:\n",
    "            color = (classes[shape[\"label\"]], classes[shape[\"label\"]], classes[shape[\"label\"]])\n",
    "            pts = np.array(shape[\"points\"], np.int32)\n",
    "            pts = pts.reshape(-1, 2)\n",
    "            mask_img = cv2.fillConvexPoly(mask_img, pts, color)\n",
    "            cv2.imwrite(os.path.join(mask_out_dir, filename.replace(\".json\", \".png\")), mask_img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Convert COCO annotation file into LIP parsing mask image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['info', 'images', 'year', 'licenses', 'type', 'annotations', 'categories'])\n"
     ]
    }
   ],
   "source": [
    "# json_file = open(\"./modanet2018_instances_train.json\")\n",
    "# json_data = json.loads(json_file.read())\n",
    "# print(json_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'file_name': '0736791.jpg', 'width': 400, 'id': 736791, 'license': 3, 'height': 600}\n"
     ]
    }
   ],
   "source": [
    "# print(json_data[\"images\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for images_info in json_data[\"images\"]:\n",
    "#     filename = images_info[\"file_name\"]\n",
    "\n",
    "#     if not os.path.exists(f\"./Images/{filename}\"):\n",
    "#         print(f\"No such file {filename}\")\n",
    "#         exit()\n",
    "    \n",
    "#     print(f\"{images_info['id']} : {filename}\")\n",
    "\n",
    "# print(f\"All files OK!\")\n",
    "# print(json_data[\"annotations\"][0].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 265705/265705 [04:19<00:00, 1023.35it/s]\n"
     ]
    }
   ],
   "source": [
    "# current_img = \"\"\n",
    "\n",
    "# for annotation in tqdm(json_data[\"annotations\"]):\n",
    "    \n",
    "#     image_id = str(annotation['image_id']).zfill(7)\n",
    "#     class_id = annotation[\"category_id\"]\n",
    "\n",
    "#     # image load\n",
    "#     if not image_id == current_img:\n",
    "#         cv2.imwrite(f'./parsing_out/{current_img}.png', mask_img)\n",
    "#         mask_img = cv2.imread(f'./coco/images/{image_id}.jpg')\n",
    "#         h, w, _ = mask_img.shape\n",
    "#         mask_img = np.zeros((h, w, 3), np.int32)\n",
    "#         current_img = image_id\n",
    "#         # print(f'./Images/{image_id}.jpg')\n",
    "#         # print(mask_img.shape)\n",
    "\n",
    "#     # iterate segmentation\n",
    "#     for segmentation in annotation['segmentation']:\n",
    "#         # segmentation = annotation['segmentation']\n",
    "#         pts = np.array(segmentation, np.int32)\n",
    "#         pts = pts.reshape(-1, 2)\n",
    "#         # print(pts)\n",
    "#         # pts = pts.reshape((-1, 1, 2))\n",
    "#         mask_img = cv2.fillConvexPoly(mask_img, pts, (class_id, class_id, class_id))\n",
    "#         # print(\"success\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda116",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
